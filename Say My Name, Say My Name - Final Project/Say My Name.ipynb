{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from splinter import Browser\n",
    "import json\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WINDOWS/PC - Import splinter and set the cromedriver path\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)\n",
    "\n",
    "# MAC - Import splinter and set the cromedriver path\n",
    "#executable_path = {'executable_path': '/usr/local/bin/chromedriver'}\n",
    "#browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Convert Baby Names and Year of Birth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and read name files; add year column based on file name\n",
    "\n",
    "fileList=glob.glob(\"*.txt\")\n",
    "#def addField(fileList):\n",
    "for filename in fileList:\n",
    "    #print(filename)\n",
    "    df=pd.read_csv(filename, header=None)           \n",
    "    df['yr']=[filename.rsplit(\"b\",1)[1]]*df.shape[0]\n",
    "    #print(df['yr'])\n",
    "    df.to_csv(filename+\".csv\", index=None, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Column Headings, Concatenate files and merge to single csv file \"Concatenated.csv\"\n",
    "\n",
    "outfile=\"C:Concatenated.csv\"\n",
    "fileList=glob.glob(\"*.csv\")\n",
    "dfList=[] # create an empty list\n",
    "colnames=['Name', 'Gender', 'Count', 'Year']\n",
    "for filename in fileList:\n",
    "    #print(filename)\n",
    "    df=pd.read_csv(filename, header=None)\n",
    "    dfList.append(df)\n",
    "concatDf=pd.concat(dfList, axis=0)\n",
    "concatDf.columns=colnames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample output from the \"Concatenated.csv\" file\n",
    "concatDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CODE for splitting .txt from Year field - Leaving only the year\n",
    "newYr = concatDf[\"Year\"].str.split(\".\",n=1, expand=True)\n",
    "#newYr.head()\n",
    "concatDf[\"Year\"]=newYr[0]\n",
    "concatDf[\"txt\"]=newYr[1]\n",
    "concatDf.drop(columns=['txt'], inplace=True)\n",
    "concatDf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass dataframe to a .csv file \n",
    "concatDf.to_csv(outfile, index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load and Convert Movie Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert Movies Data from csv file\n",
    "movies=\"Cleaned_tmdb_5000_movies.csv\"\n",
    "moviesDF=pd.read_csv(movies)\n",
    "#moviesDF.head()\n",
    "#print(moviesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_tmdb_movies(path):   #df = \"Cleaned_tmdb_5000_movies.csv\"\n",
    "    df = pd.read_csv(path)\n",
    "    df['release_date'] = pd.to_datetime(df['release_date']).apply(lambda x: x.date())\n",
    "    json_columns = ['genres', 'keywords', 'production_countries', 'production_companies', 'spoken_languages']\n",
    "    for column in json_columns:\n",
    "        df[column] = df[column].apply(json.loads)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>title</th>\n",
       "      <th>cast</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Four Rooms</td>\n",
       "      <td>[{\"cast_id\": 42, \"character\": \"Ted the Bellhop...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>Star Wars</td>\n",
       "      <td>[{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>Finding Nemo</td>\n",
       "      <td>[{\"cast_id\": 8, \"character\": \"Marlin (voice)\",...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13</td>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>[{\"cast_id\": 7, \"character\": \"Forrest Gump\", \"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>American Beauty</td>\n",
       "      <td>[{\"cast_id\": 6, \"character\": \"Lester Burnham\",...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movie_id            title  \\\n",
       "0         5       Four Rooms   \n",
       "1        11        Star Wars   \n",
       "2        12     Finding Nemo   \n",
       "3        13     Forrest Gump   \n",
       "4        14  American Beauty   \n",
       "\n",
       "                                                cast  \n",
       "0  [{\"cast_id\": 42, \"character\": \"Ted the Bellhop...  \n",
       "1  [{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...  \n",
       "2  [{\"cast_id\": 8, \"character\": \"Marlin (voice)\",...  \n",
       "3  [{\"cast_id\": 7, \"character\": \"Forrest Gump\", \"...  \n",
       "4  [{\"cast_id\": 6, \"character\": \"Lester Burnham\",...  "
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Insert Credits Data from csv file\n",
    "credits=\"Cleaned_tmdb_5000_credits.csv\"\n",
    "creditsDF=pd.read_csv(credits)\n",
    "creditsDF.drop(columns=['crew'], inplace=True)\n",
    "creditsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "1\n",
      "(0, movie_id                                                    5\n",
      "title                                              Four Rooms\n",
      "cast        [{\"cast_id\": 42, \"character\": \"Ted the Bellhop...\n",
      "Name: 0, dtype: object)\n",
      "(0, movie_id                                                    5\n",
      "title                                              Four Rooms\n",
      "cast        [{\"cast_id\": 42, \"character\": \"Ted the Bellhop...\n",
      "Name: 0, dtype: object)\n",
      "2\n",
      "(1, movie_id                                                   11\n",
      "title                                               Star Wars\n",
      "cast        [{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...\n",
      "Name: 1, dtype: object)\n"
     ]
    },
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting property name enclosed in double quotes: line 1 column 5315 (char 5314)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-364-eec944fd7947>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# Convert 'cast' list of dictionaries to dataframe; drop 'credit_id' field\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mch_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcastListDF\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[1;31m#print(type(ch_data))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mch_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\__init__.py\u001b[0m in \u001b[0;36mloads\u001b[1;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[1;32m--> 348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    349\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mcls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    336\u001b[0m         \"\"\"\n\u001b[1;32m--> 337\u001b[1;33m         \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    339\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\json\\decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    351\u001b[0m         \"\"\"\n\u001b[0;32m    352\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 353\u001b[1;33m             \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    354\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    355\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Expecting value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting property name enclosed in double quotes: line 1 column 5315 (char 5314)"
     ]
    }
   ],
   "source": [
    "# NEW CELL\n",
    "\n",
    "# Extract the FIRST ROW of the \"cast\" column\n",
    "\n",
    "counter = 0 \n",
    "print(type(creditsDF))\n",
    "character_df = pd.DataFrame(columns=['cast_id', 'character', 'credit_id', 'gender', 'id', 'name', 'order', 'movie_id'])\n",
    "\n",
    "for row in creditsDF.iterrows():\n",
    "    counter = counter + 1\n",
    "    print(counter)\n",
    "    castListDF = row[1][2]\n",
    "    print(row)\n",
    "    #print(castListDF)\n",
    "    #print(type(castListDF_5))\n",
    "\n",
    "    # Convert 'cast' list of dictionaries to dataframe; drop 'credit_id' field\n",
    "    ch_data = json.loads(castListDF)\n",
    "    #print(type(ch_data))\n",
    "    ch_df = pd.DataFrame(ch_data)\n",
    "    ch_df['movie_id'] = row[1]['movie_id']\n",
    "    character_df=character_df.append(ch_df)\n",
    "        \n",
    "    try:\n",
    "        print(row)\n",
    "    except JSONDecodeError as e:\n",
    "        skip\n",
    "        #print(e)\n",
    "        #pass\n",
    "        #print('Sorry. Information not available')\n",
    "        #continue\n",
    "    except Exception as e:\n",
    "        skip\n",
    "        #print(e)\n",
    "        print('Sorry. Information not available')\n",
    "        #print 'Row Data:' ,len(row),row\n",
    "        continue\n",
    "    #print(ch_df)\n",
    "    #print(character_df)\n",
    "    #if counter >= 342:\n",
    "        #break\n",
    "\n",
    "ch_df.drop(columns=['credit_id'], inplace=True)\n",
    "character_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean data for unique values in character names\n",
    "pd.value_counts(df['character'])\n",
    "\n",
    "# Export dataframe to \"characters.csv\" file\n",
    "character_df.to_csv(\"characters.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOADING TO MYSQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "from config import remote_db_endpoint, remote_db_port\n",
    "# CHANGE THE REMOTE_DATABASE SCHEMA INFO\n",
    "from config import remote_gwsis_dbname, remote_gwsis_dbuser, remote_gwsis_dbpwd\n",
    "import pymysql\n",
    "import pandas as pd\n",
    "pymysql.install_as_MySQLdb()\n",
    "\n",
    "# CHANGE THIS endpoint: gwda-etl-project.c2supt4qfmve.us-east-2.rds.amazonaws.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(f\"mysql://{remote_gwsis_dbuser}:{remote_gwsis_dbpwd}@{remote_db_endpoint}:{remote_db_port}/{remote_gwsis_dbname}\")\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_df = pd.read_csv(\"Concatenated.csv\")\n",
    "names_load = names_df\n",
    "names_load.to_sql(name='Names', if_exists='append', con=conn, chunksize=2000000, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = pd.read_csv(\"Cleaned_tmdb_5000_movies.csv\")\n",
    "movies_load = movies_df\n",
    "movies_load.to_sql(name='Movies', if_exists='append', con=conn, chunksize=2000000, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credits_df = pd.read_csv(\"Cleaned_tmdb_5000_credits.csv\")\n",
    "credits_load = credits_df\n",
    "credits_load.to_sql(name='Characters', if_exists='append', con=conn, chunksize=2000000, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
